# üé§ R.A.D.A.R. Voice Integration System
## Complete Voice-Enabled Medical Monitoring

---

## üìã Overview

The R.A.D.A.R. Voice Integration System provides comprehensive voice capabilities for hands-free health monitoring, emergency alerts, and multi-language support for India's diverse patient population.

### üéØ Key Features

1. **üîä Text-to-Speech (TTS)** - ElevenLabs + Web Speech API fallback
2. **üéôÔ∏è Speech-to-Text (STT)** - Deepgram + Web Speech Recognition fallback
3. **üö® Emergency Voice Alerts** - Auto-speak critical health warnings
4. **üåç Multi-Language Support** - English, Hindi, Tamil, Telugu
5. **ü§ñ Voice-Enabled Chatbot** - Conversational health assistant
6. **üìû Voice Commands** - Navigation and emergency activation
7. **üëÇ Wake Word Detection** - "RADAR" activation

---

## üèóÔ∏è Architecture

### Voice Service Stack

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  VoiceProvider                      ‚îÇ
‚îÇ         (Global State Management)                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚îÇ
     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
     ‚îÇ                           ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê                 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   TTS   ‚îÇ                 ‚îÇ   STT   ‚îÇ
‚îÇ Service ‚îÇ                 ‚îÇ Service ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ                           ‚îÇ
     ‚îú‚îÄ ElevenLabs              ‚îú‚îÄ Deepgram
     ‚îî‚îÄ Web Speech API          ‚îî‚îÄ Web Speech Recognition
```

### Component Hierarchy

```
App Layout
‚îú‚îÄ‚îÄ VoiceProvider (Context)
‚îÇ   ‚îú‚îÄ‚îÄ VoiceControlPanel (Dashboard)
‚îÇ   ‚îú‚îÄ‚îÄ EmergencyVoiceAlert (Dashboard)
‚îÇ   ‚îú‚îÄ‚îÄ EmergencyVoiceButton (Floating)
‚îÇ   ‚îî‚îÄ‚îÄ ChatWidget (Voice-enabled)
```

---

## üîß Implementation Details

### 1. Core Services (`src/lib/voice/voiceService.ts`)

#### ElevenLabs TTS Service
```typescript
class ElevenLabsTTSService {
  async speak(text: string, options: {
    language?: LanguageCode;
    urgency?: 'normal' | 'urgent' | 'critical';
    onStart?: () => void;
    onEnd?: () => void;
    onError?: (error: Error) => void;
  }): Promise<void>
}
```

**Features:**
- **Model**: `eleven_multilingual_v2` (supports 29 languages)
- **Voice Presets**: Normal, Urgent, Critical (different stability/style)
- **Fallback**: Web Speech API if ElevenLabs unavailable
- **Audio Format**: MP3 streaming

**Configuration:**
```typescript
export const VOICE_PRESETS = {
  normal: { stability: 0.7, similarity_boost: 0.7, style: 0.3 },
  urgent: { stability: 0.9, similarity_boost: 0.8, style: 0.6 },
  critical: { stability: 1.0, similarity_boost: 0.9, style: 0.8 },
}
```

#### Deepgram STT Service
```typescript
class DeepgramSTTService {
  async startListening(options: {
    language?: LanguageCode;
    onTranscript?: (text: string, isFinal: boolean) => void;
    onError?: (error: Error) => void;
    onEnd?: () => void;
  }): Promise<MediaRecorder | null>
}
```

**Features:**
- **Model**: `nova-2` (highest accuracy)
- **Real-time**: Live transcription with interim results
- **Languages**: English, Hindi, Tamil, Telugu
- **Format**: WebM audio streaming
- **Fallback**: Web Speech Recognition API

#### Voice Command Parser
```typescript
export class VoiceCommandParser {
  static parseCommand(transcript: string): {
    intent: string;
    confidence: number;
    entities: Record<string, any>;
  } | null
}
```

**Supported Commands:**

| Category | Examples | Intent |
|----------|----------|--------|
| Emergency | "emergency", "help", "call doctor" | `emergency` |
| Navigation | "show dashboard", "go to doctor" | `navigate` |
| Query | "what is my heart rate?" | `query_vitals` |
| Conversation | "should i worry?", "explain this" | `conversation` |

**Multi-Language Support:**
- Hindi: ‡§Ü‡§™‡§æ‡§§‡§ï‡§æ‡§≤, ‡§Æ‡§¶‡§¶, ‡§Æ‡•á‡§∞‡§æ, ‡§¨‡§§‡§æ‡§ì
- Tamil: ‡ÆÖ‡Æµ‡Æö‡Æ∞‡ÆÆ‡Øç, ‡Æâ‡Æ§‡Æµ‡Æø, ‡Æé‡Æ©‡Øç, ‡Æö‡Øä‡Æ≤‡Øç‡Æ≤‡ØÅ
- Telugu: ‡∞Ö‡∞§‡±ç‡∞Ø‡∞µ‡∞∏‡∞∞‡∞Ç, ‡∞∏‡∞π‡∞æ‡∞Ø‡∞Ç, ‡∞®‡∞æ, ‡∞ö‡±Ü‡∞™‡±ç‡∞™‡±Å

---

### 2. Voice Context (`src/contexts/VoiceContext.tsx`)

#### State Management
```typescript
interface VoiceState {
  isSpeaking: boolean;
  ttsQueue: string[];
  isListening: boolean;
  transcript: string;
  interimTranscript: string;
  language: LanguageCode;
  voiceEnabled: boolean;
  autoSpeak: boolean;
  wakeWordActive: boolean;
}
```

#### Key Methods

**Text-to-Speech:**
```typescript
speak(text: string, options?: {
  urgency?: 'normal' | 'urgent' | 'critical';
  priority?: boolean;
}): Promise<void>
```
- `priority: true` ‚Üí Skip queue, speak immediately
- `priority: false` ‚Üí Add to queue, speak sequentially

**Speech-to-Text:**
```typescript
startListening(): Promise<void>
stopListening(): void
```
- Auto-detects microphone
- Provides interim results
- Auto-executes commands on final transcript

**Wake Word Detection:**
```typescript
toggleWakeWord(): void
```
- Listens for "RADAR" continuously
- Responds with "Yes, how can I help?"
- Activates full listening mode

---

### 3. UI Components

#### VoiceControlPanel (`src/components/voice/VoiceControlPanel.tsx`)

**Features:**
- Language selector (EN/HI/TA/TE)
- Voice input button (mic icon)
- Real-time transcript display
- Speaking indicator
- Auto-speak toggle
- Wake word toggle
- Voice test button
- Command help guide

**Layout:**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Voice Assistant         [Disable]  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Language: English ‚ñº                ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ ‚îÇ  üé§ Start Voice Command        ‚îÇ ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ ‚îÇ üìù Transcript: "show dashboard"‚îÇ ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Voice Features                     ‚îÇ
‚îÇ ‚ö†Ô∏è Emergency Alerts    [On]        ‚îÇ
‚îÇ üì° Wake Word "RADAR"   [Off]       ‚îÇ
‚îÇ [Test Voice]                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### EmergencyVoiceAlert (`src/components/voice/EmergencyVoiceAlert.tsx`)

**Auto-Alert Logic:**
```typescript
// Triggers when:
1. Urgency level increases (GREEN ‚Üí YELLOW ‚Üí ORANGE ‚Üí RED ‚Üí CRITICAL)
2. Cooldown period has passed

Cooldown Periods:
- CRITICAL: 30 seconds
- RED: 1 minute
- ORANGE: 2 minutes
- YELLOW: 3 minutes
```

**Alert Messages (Multi-Language):**

**English:**
- CRITICAL: "Critical alert! Your vital signs require immediate medical attention..."
- Parameter-specific: "Your urea level is elevated at {value} mg/dL..."

**Hindi:**
- CRITICAL: "‡§ó‡§Ç‡§≠‡•Ä‡§∞ ‡§ö‡•á‡§§‡§æ‡§µ‡§®‡•Ä! ‡§Ü‡§™‡§ï‡•á ‡§Æ‡§π‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§∏‡§Ç‡§ï‡•á‡§§‡•ã‡§Ç ‡§ï‡•ã ‡§§‡§§‡•ç‡§ï‡§æ‡§≤ ‡§ö‡§ø‡§ï‡§ø‡§§‡•ç‡§∏‡§æ ‡§ß‡•ç‡§Ø‡§æ‡§® ‡§ï‡•Ä ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï‡§§‡§æ ‡§π‡•à..."

**Tamil:**
- CRITICAL: "‡ÆÆ‡ØÅ‡Æï‡Øç‡Æï‡Æø‡ÆØ‡ÆÆ‡Ææ‡Æ© ‡Æé‡Æö‡Øç‡Æö‡Æ∞‡Æø‡Æï‡Øç‡Æï‡Øà! ‡Æâ‡Æô‡Øç‡Æï‡Æ≥‡Øç ‡Æâ‡ÆØ‡Æø‡Æ∞‡Øç ‡ÆÖ‡Æ±‡Æø‡Æï‡ØÅ‡Æ±‡Æø‡Æï‡Æ≥‡ØÅ‡Æï‡Øç‡Æï‡ØÅ ‡Æâ‡Æü‡Æ©‡Æü‡Æø ‡ÆÆ‡Æ∞‡ØÅ‡Æ§‡Øç‡Æ§‡ØÅ‡Æµ ‡Æï‡Æµ‡Æ©‡ÆÆ‡Øç ‡Æ§‡Øá‡Æµ‡Øà..."

**Telugu:**
- CRITICAL: "‡∞ï‡±ç‡∞≤‡∞ø‡∞∑‡±ç‡∞ü‡∞Æ‡±à‡∞® ‡∞π‡±Ü‡∞ö‡±ç‡∞ö‡∞∞‡∞ø‡∞ï! ‡∞Æ‡±Ä ‡∞Æ‡±Å‡∞ñ‡±ç‡∞Ø‡∞Æ‡±à‡∞® ‡∞∏‡∞Ç‡∞ï‡±á‡∞§‡∞æ‡∞≤‡∞ï‡±Å ‡∞§‡∞ï‡±ç‡∞∑‡∞£ ‡∞µ‡±à‡∞¶‡±ç‡∞Ø ‡∞∂‡±ç‡∞∞‡∞¶‡±ç‡∞ß ‡∞Ö‡∞µ‡∞∏‡∞∞‡∞Ç..."

#### EmergencyVoiceButton (`src/components/voice/EmergencyVoiceButton.tsx`)

**Floating SOS Button:**
- Fixed position: `bottom-24 right-6`
- Size: `64x64px` red circular button
- Animation: Pulsing ring effect
- Action: Immediate voice feedback + navigate to `/action`

```typescript
handleEmergency() {
  speak("Emergency activated. Contacting medical team now.", {
    urgency: 'critical',
    priority: true,
  });
  router.push('/action');
}
```

#### Voice-Enabled Chatbot (`src/components/chat/chat-widget.tsx`)

**New Features:**
1. **Voice Input Button** (üé§ mic icon)
   - Start/stop listening
   - Animated when active
   - Auto-sends transcript

2. **Voice Output** (üîä speaker icon)
   - Speaks bot responses automatically
   - Skippable by user
   - Respects voice enabled setting

3. **Status Indicators:**
   - üî¥ Listening: "Listening: [interim transcript]..."
   - üü¢ Speaking: "Speaking..."

**Integration:**
```typescript
// Auto-send after voice input
useEffect(() => {
  if (transcript && isOpen) {
    setInputValue(transcript);
    setTimeout(() => handleSendMessage(), 500);
  }
}, [transcript]);

// Auto-speak bot responses
useEffect(() => {
  if (lastMessage.sender === 'bot' && voiceEnabled) {
    speak(lastMessage.text);
  }
}, [messages]);
```

---

## üåê Multi-Language System

### Supported Languages

| Code | Name | Voice (ElevenLabs) | Medical Terms Support |
|------|------|-------------------|----------------------|
| `en` | English | Rachel | ‚úÖ Full |
| `hi` | Hindi | Adam (Multilingual) | ‚úÖ Translated |
| `ta` | Tamil | Adam (Multilingual) | ‚úÖ Translated |
| `te` | Telugu | Adam (Multilingual) | ‚úÖ Translated |

### Translation Strategy

**Medical Parameters:**
- Urea: ‡§Ø‡•Ç‡§∞‡§ø‡§Ø‡§æ (Hindi), ‡ÆØ‡ØÇ‡Æ∞‡Æø‡ÆØ‡Ææ (Tamil), ‡∞Ø‡±Ç‡∞∞‡∞ø‡∞Ø‡∞æ (Telugu)
- Heart Rate: ‡§π‡•É‡§¶‡§Ø ‡§ó‡§§‡§ø, ‡Æá‡Æ§‡ÆØ ‡Æ§‡ØÅ‡Æü‡Æø‡Æ™‡Øç‡Æ™‡ØÅ, ‡∞π‡±É‡∞¶‡∞Ø ‡∞∏‡±ç‡∞™‡∞Ç‡∞¶‡∞®
- Blood Pressure: ‡§∞‡§ï‡•ç‡§§‡§ö‡§æ‡§™, ‡Æá‡Æ∞‡Æ§‡Øç‡Æ§ ‡ÆÖ‡Æ¥‡ØÅ‡Æ§‡Øç‡Æ§‡ÆÆ‡Øç, ‡∞∞‡∞ï‡±ç‡∞§‡∞™‡±ã‡∞ü‡±Å
- Oxygen: ‡§ë‡§ï‡•ç‡§∏‡•Ä‡§ú‡§®, ‡ÆÜ‡Æï‡Øç‡Æ∏‡Æø‡Æú‡Æ©‡Øç, ‡∞Ü‡∞ï‡±ç‡∞∏‡∞ø‡∞ú‡∞®‡±ç

**Alert Translations (Example):**
```typescript
const ALERT_MESSAGES = {
  en: {
    urea_high: 'Your urea level is elevated at {value} mg/dL.',
  },
  hi: {
    urea_high: '‡§Ü‡§™‡§ï‡§æ ‡§Ø‡•Ç‡§∞‡§ø‡§Ø‡§æ ‡§∏‡•ç‡§§‡§∞ {value} ‡§Æ‡§ø‡§≤‡•Ä‡§ó‡•ç‡§∞‡§æ‡§Æ ‡§™‡•ç‡§∞‡§§‡§ø ‡§°‡•á‡§∏‡•Ä‡§≤‡•Ä‡§ü‡§∞ ‡§™‡§∞ ‡§¨‡§¢‡§º‡§æ ‡§π‡•Å‡§Ü ‡§π‡•à‡•§',
  },
  // ... Tamil, Telugu
}
```

---

## üîë Environment Configuration

### Required API Keys

**.env.local:**
```bash
# ElevenLabs (TTS)
ELEVENLABS_API_KEY=your_elevenlabs_key_here
NEXT_PUBLIC_ELEVENLABS_API_KEY=your_elevenlabs_key_here

# Deepgram (STT)
DEEPGRAM_API_KEY=your_deepgram_key_here
NEXT_PUBLIC_DEEPGRAM_API_KEY=your_deepgram_key_here

# Groq (LLM - already configured)
GROQ_API_KEY=your_groq_api_key
```

### Getting API Keys

1. **ElevenLabs:**
   - Visit: https://elevenlabs.io/
   - Sign up for free tier (10,000 characters/month)
   - Navigate to Profile ‚Üí API Keys
   - Copy key to `.env.local`

2. **Deepgram:**
   - Visit: https://deepgram.com/
   - Sign up for free tier ($200 credit)
   - Create new API key in console
   - Copy key to `.env.local`

### Fallback Behavior

If API keys are not configured:
- **TTS**: Falls back to Web Speech API (`window.speechSynthesis`)
- **STT**: Falls back to Web Speech Recognition (`window.SpeechRecognition`)

**Limitations of Fallbacks:**
- Web Speech API: Limited voice quality, fewer languages
- Web Speech Recognition: Lower accuracy, may not work in all browsers

---

## üöÄ Usage Guide

### For Developers

#### 1. Using Voice in Components

```typescript
import { useVoice } from '@/contexts/VoiceContext';

export function MyComponent() {
  const { 
    speak, 
    startListening, 
    isListening, 
    transcript,
    language,
    voiceEnabled 
  } = useVoice();

  const handleSpeak = () => {
    speak('Hello from R.A.D.A.R.', { urgency: 'normal' });
  };

  const handleListen = async () => {
    await startListening();
    // transcript will update automatically
  };

  useEffect(() => {
    if (transcript) {
      console.log('User said:', transcript);
    }
  }, [transcript]);

  return (
    <div>
      <button onClick={handleSpeak}>Speak</button>
      <button onClick={handleListen} disabled={!voiceEnabled}>
        {isListening ? 'Listening...' : 'Start Listening'}
      </button>
    </div>
  );
}
```

#### 2. Emergency Alerts

```typescript
// Auto-trigger based on urgency
const { speak, autoSpeak } = useVoice();
const { latestData } = useSensorData();

useEffect(() => {
  if (autoSpeak && latestData.urgency === 'CRITICAL') {
    speak('Critical alert detected!', {
      urgency: 'critical',
      priority: true, // Skip queue, speak immediately
    });
  }
}, [latestData.urgency]);
```

#### 3. Custom Voice Commands

```typescript
import { VoiceCommandParser } from '@/lib/voice/voiceService';

const { transcript, executeCommand } = useVoice();

useEffect(() => {
  if (transcript) {
    const command = VoiceCommandParser.parseCommand(transcript);
    
    if (command?.intent === 'custom_action') {
      // Handle your custom action
      handleCustomAction(command.entities);
    }
  }
}, [transcript]);
```

### For Users

#### 1. Basic Voice Commands

**Emergency:**
- "Emergency"
- "Help"
- "Call doctor"
- "Critical"

**Navigation:**
- "Show dashboard"
- "Go to cardiovascular"
- "Open chatbot"
- "Show doctor page"

**Queries:**
- "What is my heart rate?"
- "Check my vitals"
- "Tell me my urea level"

**Conversation:**
- "Should I worry?"
- "Am I okay?"
- "Explain this reading"

#### 2. Wake Word Activation

1. Enable "Wake Word" in Voice Control Panel
2. Say "RADAR" or "Hey RADAR"
3. System responds: "Yes, how can I help?"
4. Speak your command

#### 3. Multi-Language Usage

1. Open Voice Control Panel
2. Select language: English / ‡§π‡§ø‡§Ç‡§¶‡•Ä / ‡Æ§‡ÆÆ‡Æø‡Æ¥‡Øç / ‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å
3. All alerts and responses will be in selected language
4. Voice commands work in native language

---

## üéõÔ∏è Configuration Options

### Voice Preferences (Stored in localStorage)

```typescript
// User settings
{
  'radar-voice-language': 'en' | 'hi' | 'ta' | 'te',
  'radar-voice-enabled': 'true' | 'false',
  'radar-auto-speak': 'true' | 'false',
}
```

### Voice Presets

```typescript
// Modify urgency presets
export const VOICE_PRESETS = {
  normal: { 
    stability: 0.7,        // 0-1: Higher = more consistent
    similarity_boost: 0.7, // 0-1: Higher = closer to original voice
    style: 0.3            // 0-1: Higher = more expressive
  },
  urgent: {
    stability: 0.9,
    similarity_boost: 0.8,
    style: 0.6
  },
  critical: {
    stability: 1.0,
    similarity_boost: 0.9,
    style: 0.8
  },
}
```

---

## üß™ Testing

### Manual Testing Checklist

- [ ] **TTS (Text-to-Speech)**
  - [ ] Click "Test Voice" button
  - [ ] Hear voice in selected language
  - [ ] Change language and test again

- [ ] **STT (Speech-to-Text)**
  - [ ] Click "Start Voice Command"
  - [ ] Speak a command
  - [ ] See transcript appear
  - [ ] Command executes correctly

- [ ] **Emergency Alerts**
  - [ ] Simulate critical vitals
  - [ ] Hear automatic alert
  - [ ] Check alert in multiple languages

- [ ] **Wake Word**
  - [ ] Enable wake word detection
  - [ ] Say "RADAR"
  - [ ] System responds and activates

- [ ] **Voice Chatbot**
  - [ ] Open chatbot
  - [ ] Click mic button
  - [ ] Ask a question
  - [ ] Hear bot response

- [ ] **Emergency Button**
  - [ ] Click floating red SOS button
  - [ ] Hear emergency message
  - [ ] Redirects to action page

### Browser Compatibility

| Feature | Chrome | Edge | Safari | Firefox |
|---------|--------|------|--------|---------|
| ElevenLabs TTS | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |
| Deepgram STT | ‚úÖ | ‚úÖ | ‚ö†Ô∏è | ‚ö†Ô∏è |
| Web Speech API | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |
| Web Speech Recognition | ‚úÖ | ‚úÖ | ‚ùå | ‚ùå |

‚ö†Ô∏è = May require WebM support
‚ùå = Not supported (falls back to other methods)

---

## üìä Performance

### TTS Latency
- **ElevenLabs**: 200-500ms (streaming)
- **Web Speech API**: 50-100ms (instant)

### STT Latency
- **Deepgram**: Real-time (< 300ms)
- **Web Speech Recognition**: Real-time (< 200ms)

### Data Usage
- **TTS (1 minute speech)**: ~100KB (ElevenLabs MP3)
- **STT (1 minute recording)**: ~600KB (WebM upload)

### Optimization Tips
1. **Queue Management**: Use `priority: true` only for critical alerts
2. **Cooldown Periods**: Prevent alert spam with cooldown logic
3. **Language Caching**: Cache translated messages in memory
4. **Audio Compression**: Use MP3 for TTS, WebM for STT

---

## üêõ Troubleshooting

### Common Issues

**1. "Microphone access denied"**
- **Solution**: Grant microphone permission in browser settings
- Chrome: Settings ‚Üí Privacy ‚Üí Site Settings ‚Üí Microphone

**2. "Voice not working"**
- Check API keys in `.env.local`
- Verify network connection
- Try fallback (Web Speech API)

**3. "Wake word not detecting"**
- Speak clearly: "RADAR" (2 syllables)
- Check microphone sensitivity
- Ensure wake word is enabled

**4. "Wrong language spoken"**
- Check language selector in Voice Control Panel
- Verify `localStorage` setting
- Restart voice service

**5. "Alerts not speaking automatically"**
- Enable "Auto-Speak" in Voice Control Panel
- Check voice is enabled globally
- Verify urgency level triggers alert

---

## üîÆ Future Enhancements

### Planned Features
1. **Custom Wake Words** - User-defined activation phrases
2. **Voice Biometrics** - Patient identification via voice
3. **Emotion Detection** - Detect stress/panic in voice
4. **Offline Mode** - Download voice models for offline use
5. **More Languages** - Expand to 10+ Indian languages
6. **Voice Analytics** - Track usage patterns and improve accuracy

### Technical Improvements
1. **WebRTC for real-time communication**
2. **Edge TTS** - On-device processing
3. **Voice Activity Detection (VAD)** - Better wake word accuracy
4. **Speaker Diarization** - Multi-person conversations

---

## üìù API Reference

### VoiceProvider Methods

```typescript
interface VoiceContextValue {
  // State
  isSpeaking: boolean;
  isListening: boolean;
  transcript: string;
  interimTranscript: string;
  language: LanguageCode;
  voiceEnabled: boolean;
  autoSpeak: boolean;
  wakeWordActive: boolean;
  
  // TTS Methods
  speak(text: string, options?: {
    urgency?: 'normal' | 'urgent' | 'critical';
    priority?: boolean;
  }): Promise<void>;
  stopSpeaking(): void;
  clearQueue(): void;
  
  // STT Methods
  startListening(): Promise<void>;
  stopListening(): void;
  
  // Configuration
  setLanguage(lang: LanguageCode): void;
  toggleVoice(): void;
  toggleAutoSpeak(): void;
  toggleWakeWord(): void;
  
  // Commands
  executeCommand(transcript: string): void;
}
```

---

## üìö Resources

### Documentation
- [ElevenLabs API Docs](https://docs.elevenlabs.io/)
- [Deepgram API Docs](https://developers.deepgram.com/)
- [Web Speech API (MDN)](https://developer.mozilla.org/en-US/docs/Web/API/Web_Speech_API)

### Code Examples
- `src/lib/voice/voiceService.ts` - Core services
- `src/contexts/VoiceContext.tsx` - State management
- `src/components/voice/` - UI components

---

## ‚úÖ Summary

The R.A.D.A.R. Voice Integration System provides:

‚úÖ **Hands-free Operation** - Voice commands for navigation and queries
‚úÖ **Emergency Alerts** - Auto-speak critical health warnings
‚úÖ **Multi-Language** - English, Hindi, Tamil, Telugu support
‚úÖ **Production-Ready** - ElevenLabs + Deepgram with fallbacks
‚úÖ **User-Friendly** - Simple UI, clear feedback
‚úÖ **Accessible** - Helps patients with limited literacy/mobility

**Ready for deployment in Indian healthcare market! üáÆüá≥**
